{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "test_id      0\n",
      "question1    2\n",
      "question2    4\n",
      "dtype: int64\n",
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       0\n",
      "question2       0\n",
      "is_duplicate    0\n",
      "dtype: int64\n",
      "test_id      0\n",
      "question1    0\n",
      "question2    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import difflib\n",
    "\n",
    "def load_data(path):\n",
    "    train = pd.read_csv(path+'/train.csv')\n",
    "    test = pd.read_csv(path+'/test.csv')\n",
    "    y = train['is_duplicate']\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def fill_missing_values(train, test):\n",
    "    # Check for any null values\n",
    "    print(train.isnull().sum())\n",
    "    print(test.isnull().sum())\n",
    "    \n",
    "    # We find 2 null values in train and test both\n",
    "    # Replace them with an 'empty' string\n",
    "    train = train.fillna('empty')\n",
    "    test = test.fillna('empty')\n",
    "    return train, test\n",
    "\n",
    "    \n",
    "def clean_text(text, remove_stopwords=True, stemming=False):\n",
    "    \n",
    "    \n",
    "     # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"\", text)\n",
    "    text = re.sub(r\"What's\", \"\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"I'm\", \"I am\", text)\n",
    "    text = re.sub(r\" m \", \" am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e-mail\", \"email\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
    "    text = re.sub(r\" usa \", \" America \", text)\n",
    "    text = re.sub(r\" USA \", \" America \", text)\n",
    "    text = re.sub(r\" u s \", \" America \", text)\n",
    "    text = re.sub(r\" uk \", \" England \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text)\n",
    "    text = re.sub(r\"india\", \"India\", text)\n",
    "    text = re.sub(r\"switzerland\", \"Switzerland\", text)\n",
    "    text = re.sub(r\"china\", \"China\", text)\n",
    "    text = re.sub(r\"chinese\", \"Chinese\", text) \n",
    "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
    "    text = re.sub(r\"intially\", \"initially\", text)\n",
    "    text = re.sub(r\"quora\", \"Quora\", text)\n",
    "    text = re.sub(r\" dms \", \"direct messages \", text)  \n",
    "    text = re.sub(r\"demonitization\", \"demonetization\", text) \n",
    "    text = re.sub(r\"actived\", \"active\", text)\n",
    "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
    "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text) \n",
    "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text)\n",
    "    text = re.sub(r\"\\0rs \", \" rs \", text) \n",
    "    text = re.sub(r\"calender\", \"calendar\", text)\n",
    "    text = re.sub(r\"ios\", \"operating system\", text)\n",
    "    text = re.sub(r\"gps\", \"GPS\", text)\n",
    "    text = re.sub(r\"gst\", \"GST\", text)\n",
    "    text = re.sub(r\"programing\", \"programming\", text)\n",
    "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
    "    text = re.sub(r\"dna\", \"DNA\", text)\n",
    "    text = re.sub(r\"III\", \"3\", text) \n",
    "    text = re.sub(r\"the US\", \"America\", text)\n",
    "    text = re.sub(r\"Astrology\", \"astrology\", text)\n",
    "    text = re.sub(r\"Method\", \"method\", text)\n",
    "    text = re.sub(r\"Find\", \"find\", text) \n",
    "    text = re.sub(r\"banglore\", \"Banglore\", text)\n",
    "    text = re.sub(r\" J K \", \" JK \", text)\n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    \n",
    "    # Remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        text = [w for w in text if not w in stop_words]\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    # Shorten words to their stems\n",
    "    if stemming:\n",
    "        text = text.split()\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "\n",
    "\n",
    "train, test = load_data('../data')\n",
    "train, test = fill_missing_values(train, test)\n",
    "\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['the','a','an','and','but','if','or','because','as','what','which','this','that','these','those','then',\n",
    "              'just','so','than','such','both','through','about','for','is','of','while','during','to','What','Which',\n",
    "              'Is','If','While','This']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_questions(question_list, questions, question_list_name, dataframe):\n",
    "    '''transform questions and display progress'''\n",
    "    for idx, question in enumerate(questions):\n",
    "        question_list.append(clean_text(question, remove_stopwords=True, stemming=True))\n",
    "        if len(question_list) % 100000 == 0:\n",
    "            progress = len(question_list)/len(dataframe) * 100\n",
    "            print(\"{} is {}% complete.\".format(question_list_name, round(progress, 1)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question2 is 0.0% complete.\n",
      "train_question2 is 0.0% complete.\n",
      "train_question2 is 0.0% complete.\n",
      "train_question2 is 0.0% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question2 = []\n",
    "process_questions(train_question2, train.question2, 'train_question2', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_question1 is 0.0% complete.\n",
      "train_question1 is 0.0% complete.\n",
      "train_question1 is 0.0% complete.\n",
      "train_question1 is 0.0% complete.\n"
     ]
    }
   ],
   "source": [
    "train_question1 = []\n",
    "process_questions(train_question1, train.question1, 'train_question1', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question1 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n",
      "test_question2 is 0.0% complete.\n"
     ]
    }
   ],
   "source": [
    "test_question1 = []\n",
    "process_questions(test_question1, test.question1, 'test_question1', test)\n",
    "\n",
    "test_question2 = []\n",
    "process_questions(test_question2, test.question2, 'test_question2', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train' (DataFrame)\n",
      "Stored 'test' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# append these clean questions back to the original dataframes\n",
    "\n",
    "train_q1_clean = pd.Series(train_question1)\n",
    "train_q2_clean = pd.Series(train_question2)\n",
    "test_q1_clean = pd.Series(test_question1)\n",
    "test_q2_clean = pd.Series(test_question2)\n",
    "\n",
    "train = pd.concat([train, train_q1_clean, train_q2_clean],  axis = 1)\n",
    "test = pd.concat([test, test_q1_clean, test_q2_clean], axis = 1)\n",
    "\n",
    "%store train\n",
    "%store test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start feature engineering\n",
    "\n",
    "def calculate_wordshare(row):\n",
    "    q1_words = {}\n",
    "    q2_words = {}\n",
    "    \n",
    "    # getting words from question 1 and 2 \n",
    "    for word in str(row['question1']).lower().split(\" \"):\n",
    "        q1_words[word] = 1\n",
    "    for word in str(row['question2']).lower().split(\" \"):\n",
    "        q2_words[word] = 1\n",
    "    if len(q1_words) == 0 and len(q2_words) == 0:\n",
    "        return 0\n",
    "    common_words_q1 = [w for w in q1_words.keys() if w in q2_words]\n",
    "    common_words_q2 = [w for w in q1_words.keys() if w in q2_words]\n",
    "    wordshare = 1.0 * (len(common_words_q1) + len(common_words_q2))/(len(q1_words) + len(q2_words))\n",
    "    return wordshare\n",
    "\n",
    "def create_featureset1(dataframe):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Description:\n",
    "    'c' at the end of the feature name indicates 'clean' which is the computed questions \n",
    "    after clean_text() and process_questions() operations above. \n",
    "    \n",
    "    We compute these features: \n",
    "    1) Length of question1 - len_q1\n",
    "    2) Length of question2 - len_q2\n",
    "    3) Length of question1 after cleaning - len_q1c\n",
    "    4) Length of question2 after cleaning - len_q2c\n",
    "    5) No of words in q1 after cleaning - words_q1c\n",
    "    6) No of words in q2 after cleaning - words_q2c\n",
    "    7) Characters in q1 after cleaning and excluding spaces - chars_q1c\n",
    "    8) Characters in q2 after cleaning and excluding spaces - chars_q2c\n",
    "    9) Average number of words shared between q1 and q2 - wordshare\n",
    "    '''\n",
    "\n",
    "    dataframe['len_q1'] = dataframe.question1.map(lambda x: len(str(x)))\n",
    "    dataframe['len_q2'] = dataframe.question2.map(lambda x: len(str(x)))\n",
    "    dataframe['len_q1c'] = dataframe[0].map(lambda x: len(str(x)))\n",
    "    dataframe['len_q2c'] = dataframe[1].map(lambda x: len(str(x)))\n",
    "\n",
    "    dataframe['words_q1c'] = dataframe[0].map(lambda x: len(str(x).split(\" \")))\n",
    "    dataframe['words_q2c'] = dataframe[1].map(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "    # Counting the characters but excluding the spaces\n",
    "    dataframe['chars_q1c'] = dataframe[0].map(lambda x: len(x) - x.count(' '))\n",
    "    dataframe['chars_q2c'] = dataframe[1].map(lambda x: len(x) - x.count(' '))\n",
    "\n",
    "    dataframe['wordshare'] = dataframe.apply(calculate_wordshare, axis=1, raw=True)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "train = create_featureset1(train)\n",
    "test = create_featureset1(test)\n",
    "\n",
    "\n",
    "train.to_pickle('../data/train.pkl')\n",
    "test.to_pickle('../data/test.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
